Naive Bayes Report


Group Member Details:

Dhruv Gupta - 2017A7PS0108H
Ritik Parkar Sachin - 2017A4PS0836H
Shivam Agarwalla - 2017A7PS1589H





Preprocessing:

1)The a1_d3.txt dataset was split into two for test and train datasets i.e 80 and 20%.
2)5-fold cross validation was used for splitting i.e. first the data for test was split from (0-0.2)*total length of dataset,then from (0.2 – 0.4) ans so on till (0.8 – 1) times the dataset.Rest was used for training.
3)Common stop words(like “,” “:” “!”) were removed for calculating the probabilities.



How to run the code:
Keeping all the files in same folder run naive_bayes.py file to get the results.



Difficulties faced:
It was found that some words that were in the test set but not in the training set reduced the accuracy so we implemented Laplace Smoothing so that the conditional probability for new words is not straightforward zero and some appropriate value.



Output Obtained For 5-fold cross validation: 

accuracy for validation step for 5 fold cross validation:
accuracy for 1 fold is : 0.7537688442211056
accuracy for 2 fold is : 0.9547738693467337
accuracy for 3 fold is : 0.96
accuracy for 4 fold is : 0.949748743718593
accuracy for 5 fold is : 0.9547738693467337

average accuracy is: 0.9146130653266331 +- 0.08048743200926886

fscore for validation step for 5 fold cross validation:
fscore for 1 fold is : 0.774468085106383
fscore for 2 fold is : 0.9292035398230087
fscore for 3 fold is : 0.9569377990430622
fscore for 4 fold is : 0.9447236180904524
fscore for 5 fold is : 0.956043956043956

average fscore is: 0.9122753996213724 +- 0.06962861653049851






